From a99b34ad82584fd0ac4ff6a4cd4d780c1a5f5f9b Mon Sep 17 00:00:00 2001
From: Vijay Dhanraj <vijay.dhanraj@intel.com>
Date: Mon, 25 Mar 2024 02:36:38 -0700
Subject: [PATCH 26/26] kvm: TDX: Implement global shared buffer

This commit removes per vcpu shared buffer and implements
a global shared buffer to pass through irq events from
host to svsm. This is done to address 2 issues:

1. AP wakeup latency: During early boot, when only BSP is
active, irq events shared in per vcpu buffer of APs take time
to service the interrupt leading to shared buffer overflow.

2.Irq event ordering: When host copies irq events to the
per vcpu shared buffer, there is no guarantee that svsm
will execute in the same order, leading to missing of
certain interrupt events.

The size of the global shared buffer is to 8K.

Signed-off-by: Vijay Dhanraj <vijay.dhanraj@intel.com>
---
 arch/x86/kvm/vmx/tdx.c | 37 ++++++++++++++++---------------------
 arch/x86/kvm/vmx/tdx.h | 23 ++++++++++++-----------
 2 files changed, 28 insertions(+), 32 deletions(-)

diff --git a/arch/x86/kvm/vmx/tdx.c b/arch/x86/kvm/vmx/tdx.c
index 438bc2d70296..b2496b3fde0f 100644
--- a/arch/x86/kvm/vmx/tdx.c
+++ b/arch/x86/kvm/vmx/tdx.c
@@ -719,7 +719,7 @@ static void td_partitioning_init(struct kvm_tdx *kvm_tdx)
 	for (i = 0; i < MAX_NUM_L2_VMS; i++) {
 		INIT_LIST_HEAD(&kvm_tdx->l2sept_list[i].head);
 		spin_lock_init(&kvm_tdx->l2sept_list[i].lock);
-		kvm_tdx->l2_pt_irq[i].num_l2_vcpus = 0;
+		kvm_tdx->l2_pt_irq[i].pinned_page = NULL;
 		memset(&kvm_tdx->l2_pt_irq[i].ioapic_pin_state, 0,
 		       sizeof(kvm_tdx->l2_pt_irq[i].ioapic_pin_state));
 	}
@@ -1610,20 +1610,20 @@ static int tdx_share_irte_info(struct kvm_vcpu *vcpu,
 	void *pinned_page;
 	struct sirte_page *sirte_base;
 	struct kvm_lapic *apic;
-	struct vcpu_tdx *tdx_vcpu = to_tdx(vcpu);
+	struct kvm_tdx *kvm_tdx = to_kvm_tdx(vcpu->kvm);
 
-	if (!tdx_vcpu->pinned_page) {
+	if (!kvm_tdx->l2_pt_irq[0].pinned_page) {
 		pr_err("%s: no shared memory available!", __func__);
 		return -1;
 	}
 
-	pinned_page = page_address(tdx_vcpu->pinned_page);
+	pinned_page = page_address(kvm_tdx->l2_pt_irq[0].pinned_page);
 	sirte_base = (struct sirte_page *)pinned_page;
 
-	spin_lock(&tdx_vcpu->sirte_lock);
+	spin_lock(&kvm_tdx->l2_pt_irq[0].sirte_lock);
 	ret = tdx_sirte_put(&sirte_base->sirte_hdr.mdata, sirte_base->data,
 			    (void *)irq_event);
-	spin_unlock(&tdx_vcpu->sirte_lock);
+	spin_unlock(&kvm_tdx->l2_pt_irq[0].sirte_lock);
 
 	if (!ret) {
 		pr_err("%s: shared buf is full!", __func__);
@@ -1640,7 +1640,8 @@ static int tdx_share_irte_info(struct kvm_vcpu *vcpu,
 out:
 	apic = vcpu->arch.apic;
 	/* delivery_mode and trig_mode are *NOT* used so setting 0 */
-	tdx_deliver_interrupt(apic, 0, 0, tdx_vcpu->shared_irte_pir);
+	tdx_deliver_interrupt(apic, 0, 0,
+			      kvm_tdx->l2_pt_irq[0].shared_irte_pir);
 
 	return ret;
 }
@@ -1744,7 +1745,7 @@ bool tdx_is_irq_event_pt(struct kvm *kvm)
 	 * FIXME: Currently SVSM only supports one VM, but layout plumbing
 	 * for multi-L2 VM support.
 	 */
-	return kvm_tdx->l2_pt_irq[0].num_l2_vcpus == kvm->created_vcpus;
+	return !!kvm_tdx->l2_pt_irq[0].pinned_page;
 }
 
 static int tdx_handle_shared_irte_header(struct kvm_vcpu *vcpu)
@@ -1752,16 +1753,16 @@ static int tdx_handle_shared_irte_header(struct kvm_vcpu *vcpu)
 	gfn_t gfn;
 	gpa_t gpa = tdvmcall_a0_read(vcpu);
 	u64 vm_idx = tdvmcall_a1_read(vcpu);
+	u64 num_shared_pages = tdvmcall_a2_read(vcpu);
 	struct page *page;
 	int npages_pinned;
 	unsigned long guest_addr;
 	void *shared_page_vaddr;
 	struct sirte_header sirte_hdr;
-	struct vcpu_tdx *tdx_vcpu = to_tdx(vcpu);
 	struct kvm_tdx *kvm_tdx = to_kvm_tdx(vcpu->kvm);
 
 	/* shared irte info already initialized, return success */
-	if (tdx_vcpu->pinned_page) {
+	if (kvm_tdx->l2_pt_irq[0].pinned_page) {
 		tdvmcall_set_return_code(vcpu, TDVMCALL_SUCCESS);
 		return 1;
 	}
@@ -1788,25 +1789,19 @@ static int tdx_handle_shared_irte_header(struct kvm_vcpu *vcpu)
 	}
 
 	guest_addr = kvm_vcpu_gfn_to_hva(vcpu, gfn);
-	npages_pinned = pin_user_pages_fast(guest_addr, 1,
+	npages_pinned = pin_user_pages_fast(guest_addr, num_shared_pages,
 					    FOLL_WRITE | FOLL_NOFAULT | FOLL_LONGTERM,
 					    &page);
-	if (npages_pinned != 1) {
+	if (npages_pinned != num_shared_pages) {
 		pr_err("%s: Failed to pin shared irte page, npage_pinned = %d",
 		       __func__, npages_pinned);
 		tdvmcall_set_return_code(vcpu, TDVMCALL_INVALID_OPERAND);
 		return 1;
 	}
-	tdx_vcpu->pinned_page = page;
-
-	/*
-	 * FIXME: Currently SVSM only supports one VM, but layout plumbing
-	 * for multi-L2 VM support.
-	 */
-	kvm_tdx->l2_pt_irq[vm_idx].num_l2_vcpus++;
+	kvm_tdx->l2_pt_irq[vm_idx].pinned_page = page;
 
 	/* Init lock for the sirte page */
-	spin_lock_init(&tdx_vcpu->sirte_lock);
+	spin_lock_init(&kvm_tdx->l2_pt_irq[vm_idx].sirte_lock);
 
 	shared_page_vaddr = page_address(page);
 	if (!shared_page_vaddr) {
@@ -1818,7 +1813,7 @@ static int tdx_handle_shared_irte_header(struct kvm_vcpu *vcpu)
 	/* Copy the first entry from the shared page to get the L1 PIR */
 	memcpy((void *)&sirte_hdr, shared_page_vaddr,
 	       sizeof(struct sirte_header));
-	tdx_vcpu->shared_irte_pir = sirte_hdr.pir;
+	kvm_tdx->l2_pt_irq[vm_idx].shared_irte_pir = sirte_hdr.pir;
 
 	tdvmcall_set_return_code(vcpu, TDVMCALL_SUCCESS);
 	return 1;
diff --git a/arch/x86/kvm/vmx/tdx.h b/arch/x86/kvm/vmx/tdx.h
index 30755f47af20..d97d1b792074 100644
--- a/arch/x86/kvm/vmx/tdx.h
+++ b/arch/x86/kvm/vmx/tdx.h
@@ -69,7 +69,15 @@ struct kvm_tdx {
 	 * buffer setup. After this, host can start sharing irq_events.
 	 */
 	struct {
-		u32 num_l2_vcpus;
+		/* Shared page to pass irq event to L1 */
+		struct page *pinned_page;
+		u8 shared_irte_pir;
+		/*
+		 * spinlock to serialize aading an irq event entry to the
+		 * shared page.
+		 */
+		spinlock_t sirte_lock;
+
 		unsigned long ioapic_pin_state[IOAPIC_NUM_PINS];
 	} l2_pt_irq[MAX_NUM_L2_VMS];
 };
@@ -141,8 +149,9 @@ struct shared_irq_event {
 	};
 } __aligned(16);
 
-#define NUM_IRQ_EVENTS					\
-	((PAGE_SIZE - sizeof(struct sirte_header)) /	\
+/* sirte page is set to 8K in size */
+#define NUM_IRQ_EVENTS						\
+	(((2 * PAGE_SIZE) - sizeof(struct sirte_header)) /	\
 	sizeof(struct shared_irq_event))
 struct sirte_page {
 	struct sirte_header sirte_hdr;
@@ -195,14 +204,6 @@ struct vcpu_tdx {
 	struct lbr_desc lbr_desc;
 
 	bool resume_l1;
-
-	/* Shared page to pass irq event to L1 */
-	struct page *pinned_page;
-	u8 shared_irte_pir;
-	/*
-	 * spinlock to serialize the entry of irq event in the shared page.
-	 */
-	spinlock_t sirte_lock;
 };
 
 static inline bool is_td(struct kvm *kvm)
-- 
2.34.1

